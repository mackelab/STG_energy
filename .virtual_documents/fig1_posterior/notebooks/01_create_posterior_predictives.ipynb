import torch
import numpy as np

from pyloric import simulate, create_prior, stats
from joblib import delayed, Parallel
from copy import deepcopy
from multiprocessing import Pool
import time


_ = torch.manual_seed(12312313)


data = np.load('/home/michael/Documents/STG_energy/results/flow/200411_flow.npz', allow_pickle=True)


flow = data['posterior'].tolist()


print(flow.sample(1))


prior = create_prior()


data = np.load("../../results/11deg_post_pred/11_deg_post_pred_close_to_obs.npz")
good_stats = data["sample_stats"]
good_params = data["sample_params"]
good_seeds = data["sample_seeds"]


from stg_energy.fig2_histograms.energy import select_ss_close_to_obs
datafile = "../../results/prior_samples_after_classifier/samples_full_3.npz"
data = np.load(datafile)
ss_prior = data["stats"]

stats_mean = np.mean(ss_prior, axis=0)
stats_std = np.std(ss_prior, axis=0)


npz = np.load("../../results/experimental_data/summstats_prep845_082_0044.npz")
observation = npz["summ_stats"]

npz = np.load("../../results/experimental_data/trace_data_845_082_0044.npz")
t = npz["t"]


num_std = np.asarray(
    [0.02, 0.02, 0.02, 0.02, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]
)


start_time = time.time()
all_samples = []
for k in range(1958, 2000):
    start_time = time.time()
    num_samples_per_iter = 2520
    flow_samples = flow.sample(num_samples_per_iter)
    seeds = torch.randint(0, 10000, (num_samples_per_iter, 1))

    params_with_seeds = torch.cat((flow_samples, seeds), axis=1).detach().numpy()

    def simulator(params_set):
        out_target = simulate(
            deepcopy(params_set[:-1].astype(np.float64)),
            seed=int(params_set[-1]),
        )
        return stats(out_target)

    simulation_outputs = Parallel(n_jobs=12)(
        delayed(simulator)(batch)
        for batch in params_with_seeds
    )

    simulation_outputs = np.asarray(simulation_outputs)

    # Just for fun and print: compute how many are good.
    good_params_new, good_dat_new, good_seeds_new = select_ss_close_to_obs(
        flow_samples,
        simulation_outputs,
        seeds.squeeze(),
        observation,
        num_std=num_std,
        stats_std=stats_std[:15],
        new_burst_position_in_ss=True
    )

    print("num of good:  ", good_params_new.shape)

    np.savez(f"../../results/11deg_post_pred/11deg_5million_predictives_for_temp/simulated/11deg_5million_predictives_for_temp_{k}.npz", params=flow_samples.detach().numpy(), stats=simulation_outputs, seeds=seeds)
    print("Overall time for iteration", k, ":   ", time.time()-start_time)






